{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reth202/Tesis_Analisis_Del_Sentimiento/blob/main/Entregable_2_Proyecto_final_19_Junio_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZqQtkvOwZvA",
        "outputId": "11d8a944-45cf-4b52-ec7c-c3581cbe9346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -g\n",
            "Collecting streamlit-lottie\n",
            "  Downloading streamlit_lottie-0.0.5-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit>=0.63 (from streamlit-lottie)\n",
            "  Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-lottie) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit>=0.63->streamlit-lottie)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit>=0.63->streamlit-lottie)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-lottie) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit>=0.63->streamlit-lottie)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-lottie)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-lottie) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-lottie) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-lottie) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-lottie) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-lottie) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-lottie) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-lottie) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-lottie) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-lottie) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-lottie)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-lottie) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-lottie) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit>=0.63->streamlit-lottie) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit, streamlit-lottie\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.35.0 streamlit-lottie-0.0.5 watchdog-4.0.1\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.1 (from gradio)\n",
            "  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m608.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=2d9f992e0741c756d196a559603ffa155dd584204ae77b5bfb251043b8851b33\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.9 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [55.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [929 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,093 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,187 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,474 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,922 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,552 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,392 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Fetched 12.9 MB in 2s (6,894 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "49 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=c490c9249d5633c24186b848e899246d67a92f311d4ecfb7669c18227100ad94\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.5.0-py3-none-manylinux_2_17_x86_64.whl (996 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.2/996.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.11-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting audeer>=1.18.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audeer-2.0.0-py3-none-any.whl (39 kB)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.1.4-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting audiofile>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audiofile-1.4.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting audmath>=1.3.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audmath-1.4.1-py3-none-any.whl (23 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.3-py3-none-manylinux_2_17_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from audobject>=0.6.1->opensmile) (7.1.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from audobject>=0.6.1->opensmile) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from audeer>=1.18.0->audinterface>=0.7.0->opensmile) (4.66.4)\n",
            "Collecting iso-639 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.1)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.25.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (0.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.19.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2024.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->audiofile>=1.3.0->audinterface>=0.7.0->opensmile) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.16.0)\n",
            "Building wheels for collected packages: iso-639\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168840 sha256=e6e91da09f5cf5f1061e975ef7cade83c9d0b150dc84d56e6bbd83322ade4af3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/78/cc/5478ca3b1c3f602eae6f8cdbd78f909c0a0bfa0bbcb5c7771f\n",
            "Successfully built iso-639\n",
            "Installing collected packages: iso-639, oyaml, iso3166, audresample, audmath, audeer, audobject, audiofile, audformat, audinterface, opensmile\n",
            "Successfully installed audeer-2.0.0 audformat-1.1.4 audinterface-1.2.1 audiofile-1.4.0 audmath-1.4.1 audobject-0.7.11 audresample-1.3.3 iso-639-0.4.5 iso3166-2.1.1 opensmile-2.5.0 oyaml-1.0\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Collecting oracledb\n",
            "  Downloading oracledb-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from oracledb) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.2.1->oracledb) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.2.1->oracledb) (2.22)\n",
            "Installing collected packages: oracledb\n",
            "Successfully installed oracledb-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -g\n",
        "!pip install streamlit-lottie\n",
        "!pip install gradio\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install -U openai-whisper\n",
        "!pip install numpy pandas scikit-learn tensorflow\n",
        "!pip install librosa\n",
        "!pip install opensmile\n",
        "!pip install soundfile\n",
        "!pip install resampy\n",
        "!pip install transformers\n",
        "!pip install scipy\n",
        "!pip install oracledb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import subprocess\n",
        "\n",
        "import librosa\n",
        "from librosa import display\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, pipeline\n",
        "from scipy.special import softmax\n",
        "\n",
        "import gradio as gr\n",
        "import whisper\n",
        "from whisper import load_model\n",
        "import shutil\n",
        "\n",
        "from datetime import datetime\n",
        "import oracledb\n",
        "from pydub import AudioSegment\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "nbOEuzG2wozR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "username = \"USER_PROYFINAL\"\n",
        "dsn = \"dbproyfinal_high\"\n",
        "pw = \"UserProyFinal#40_24\"\n",
        "wallet_pw=\"^&$#7aBcdeFgHiJkLmNpQrStUvWxYz@!%\""
      ],
      "metadata": {
        "id": "3QjF8Z0kxXqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MR0pStP_9KU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac63b8d-6e91-48b2-82ae-50156eedff5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/drive/MyDrive/TrabajoFinal/Codigo/ColabVersiones/opensmile-3.0.2-linux-x86_64/bin/SMILExtract\n",
        "!chmod +r \"/content/drive/MyDrive/TrabajoFinal/Codigo/ColabVersiones/opensmile-3.0.2-linux-x86_64/config/is09-13/IS09_emotion.conf\""
      ],
      "metadata": {
        "id": "mE2X7d2yxd7R",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/'\n",
        "lst = []\n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "      try:\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "        file = file[6:8]\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      except ValueError:\n",
        "        continue"
      ],
      "metadata": {
        "id": "n6TpYHQl2k5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para extraer características con OpenSMILE\n",
        "def extract_features(audio_path, output_path, config_path=\"/content/drive/MyDrive/TrabajoFinal/Codigo/ColabVersiones/opensmile-3.0.2-linux-x86_64/config/is09-13/IS09_emotion.conf\"):\n",
        "    !chmod +r \"{config_path}\"\n",
        "\n",
        "    # Construir el comando para ejecutar OpenSMILE\n",
        "    command = f'\"/content/drive/MyDrive/TrabajoFinal/Codigo/ColabVersiones/opensmile-3.0.2-linux-x86_64/bin/SMILExtract\" -C \"{config_path}\" -I \"{audio_path}\" -O \"{output_path}\"'\n",
        "\n",
        "    # Ejecutar el comando y capturar el resultado\n",
        "    result = subprocess.run(command, shell=True, capture_output=True)\n",
        "\n",
        "    # Manejo de errores si el proceso no termina con éxito\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Error al ejecutar OpenSMILE:\\n{result.stderr.decode('utf-8')}\")\n",
        "        return \"Error al ejecutar OpenSMILE\"\n",
        "    else:\n",
        "        return result"
      ],
      "metadata": {
        "id": "vdwC0wBs9hgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio de datos\n",
        "data_dir = '/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/'\n",
        "output_dir = '/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/features'\n",
        "\n",
        "# Crear el directorio de salida si no existe\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Inicializar una lista para almacenar los datos\n",
        "data = []\n",
        "\n",
        "# Recorrer cada carpeta de emociones\n",
        "for emotion in os.listdir(data_dir):\n",
        "    emotion_dir = os.path.join(data_dir, emotion)\n",
        "    if os.path.isdir(emotion_dir):\n",
        "        # Recorrer cada archivo de audio en la carpeta de emociones\n",
        "        for audio_file in os.listdir(emotion_dir):\n",
        "            if audio_file.endswith('.wav'):\n",
        "                audio_path = os.path.join(emotion_dir, audio_file)\n",
        "                AudioSinLaExtension = os.path.splitext(audio_file)[0]\n",
        "                output_path = os.path.join(output_dir, f\"{emotion}_{AudioSinLaExtension}.csv\")\n",
        "\n",
        "                # Extraer características\n",
        "                extract_features(audio_path, output_path)\n",
        "\n",
        "                # Leer las características extraídas\n",
        "                with open(output_path, 'r') as file:\n",
        "                    lines = file.readlines()\n",
        "\n",
        "                # Encontrar la línea con los datos (después de @data)\n",
        "                data_start_index = lines.index('@data\\n') + 1\n",
        "\n",
        "                # Extraer los nombres de los atributos y los valores correspondientes\n",
        "                feature_names = []\n",
        "                feature_values = []\n",
        "\n",
        "                for line in lines:\n",
        "                    if line.startswith('@attribute'):\n",
        "                        parts = line.split()\n",
        "                        feature_names.append(parts[1])\n",
        "                    elif not line.startswith('@') and line.strip():\n",
        "                        feature_values = line.strip().split(',')\n",
        "\n",
        "\n",
        "                # Crear un diccionario con las características y sus valores\n",
        "                feature_data = {feature_names[i]: float(feature_values[i]) if feature_values[i] != '?' else None for i in range(1, len(feature_values))}\n",
        "                feature_data['label'] = emotion\n",
        "\n",
        "                # Añadir las características a la lista de datos\n",
        "                data.append(feature_data)\n",
        "\n",
        "# Combinar todos los datos en un DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Guardar los datos en un archivo CSV\n",
        "df.to_csv('/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/features/features.csv', index=False)"
      ],
      "metadata": {
        "id": "MDlWlX94234M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer el archivo CSV de características\n",
        "data = pd.read_csv('/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/features/features.csv')\n",
        "\n",
        "# Separar características y etiquetas, excluyendo la columna 'class'\n",
        "X = data.drop(columns=['label', 'class'])\n",
        "y = data['label']\n",
        "\n",
        "# Codificar las etiquetas\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Convertir todas las columnas a numéricas (ignorando errores)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Eliminar filas con valores faltantes después de la conversión\n",
        "X = X.dropna()\n",
        "y_encoded = y_encoded[X.index]  # Ajustar y_encoded para coincidir con el índice de X\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características usando StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo\n",
        "model_voice = Sequential()\n",
        "model_voice.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model_voice.add(Dense(64, activation='relu'))\n",
        "model_voice.add(Dense(len(encoder.classes_), activation='softmax'))  # Asumiendo 3 clases de salida\n",
        "\n",
        "# Compilar el modelo\n",
        "model_voice.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_voice.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model_voice.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "JWZDdK9s30Lp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49cd2c7-a166-4337-f0ef-6b19b4614103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 3s 14ms/step - loss: 0.5195 - accuracy: 0.8712 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9987 - val_loss: 0.0227 - val_accuracy: 0.9950\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9950\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9975\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9975\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9975\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9975\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 8.5607e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 6.9323e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9975\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 5.7360e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 4.8023e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9975\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 4.1006e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 3.5424e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 3.0806e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9975\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 2.7074e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 2.4029e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9975\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 2.1424e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.9234e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9975\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 1.7346e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9975\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.5722e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9975\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9975\n",
            "Accuracy: 0.9975000023841858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Establishing a connection to the Oracle database\n",
        "try:\n",
        "    conn = oracledb.connect(\n",
        "    user= username,\n",
        "    password= pw,\n",
        "    dsn= dsn,\n",
        "    #Colocar ruta del walet en la maquina donde se ejecute, el wallet debe estar descomprimido\n",
        "    config_dir=r'/content/drive/MyDrive/TrabajoFinal/Codigo/DB/Wallet_DBPROYFINAL',\n",
        "    wallet_location=r'/content/drive/MyDrive/TrabajoFinal/Codigo/DB/Wallet_DBPROYFINAL',\n",
        "    wallet_password=wallet_pw\n",
        "    )\n",
        "    # Print the version of the database to confirm connection\n",
        "    print(conn.version)\n",
        "except Exception as err:\n",
        "    print(\"Error en la conexión a la base de datos\", err)\n",
        "\n",
        "cur_01=conn.cursor()\n",
        "\n",
        "\n",
        "##Cierra la conexion de la base de datos\n",
        "#conn.close()\n",
        "\n",
        "def write_db(pfile_name, pupload_date, pfile_size, pclient, pcalldate, pparticipants,  pemployee, pai_value):\n",
        "    ##Instrucciones para consultar datos de la tabla prueba2\n",
        "    try:\n",
        "        insert_datos = '''insert into analisis_sentimientos(file_name,\n",
        "        upload_date,\n",
        "        file_size,\n",
        "        client,\n",
        "        calldate,\n",
        "        participants,\n",
        "        employee,\n",
        "        ai_value)\n",
        "        values(:tagfile_name, :tagupload_date, :tagfile_size, :tagclient, :tagcalldate, :tagparticipants,  :tagemployee, :tagai_value)'''\n",
        "        cur_01.execute(insert_datos,tagfile_name=pfile_name, tagupload_date=pupload_date, tagfile_size=pfile_size, tagclient=pclient, tagcalldate=pcalldate, tagparticipants=pparticipants,  tagemployee=pemployee,tagai_value=pai_value)\n",
        "    except Exception as err:\n",
        "        print(\"Error insertando datos\",err)\n",
        "    else:\n",
        "        print(\"Datos insertados correctamente\")\n",
        "        conn.commit()\n",
        "\n",
        "def analisis_sentimiento_voz(audio_path):\n",
        "\n",
        "    audio_sin_extension = os.path.splitext(audio_path)[0]\n",
        "\n",
        "    new_output_path = os.path.join(\"/content/drive/MyDrive/TrabajoFinal/AudiosCargados/\", audio_sin_extension+\".csv\")\n",
        "\n",
        "    output_dir_audio = \"/content/drive/MyDrive/TrabajoFinal/AudiosCargados/\"\n",
        "\n",
        "    # Crear el directorio de salida si no existe\n",
        "    os.makedirs(output_dir_audio, exist_ok=True)\n",
        "\n",
        "    # Inicializar una lista para almacenar los datos\n",
        "    data_new_audio = []\n",
        "\n",
        "    # Extraer características del nuevo archivo de audio\n",
        "    valor = extract_features(audio_path, new_output_path)\n",
        "\n",
        "    if valor == \"Error al ejecutar OpenSMILE\":\n",
        "      return \"Error al extraer características del nuevo archivo de audio\"\n",
        "\n",
        "    else:\n",
        "        with open(new_output_path, 'r') as file:\n",
        "            lines_new_audio = file.readlines()\n",
        "\n",
        "        # Encontrar la línea con los datos (después de @data)\n",
        "        data_start_index = lines.index('@data\\n') + 1\n",
        "\n",
        "        # Extraer los nombres de los atributos y los valores correspondientes\n",
        "        feature_names_new_audio = []\n",
        "        feature_values_new_audio = []\n",
        "\n",
        "        for line_new_audio in lines_new_audio:\n",
        "          if line_new_audio.startswith('@attribute'):\n",
        "            parts = line_new_audio.split()\n",
        "            feature_names_new_audio.append(parts[1])\n",
        "          elif not line_new_audio.startswith('@') and line_new_audio.strip():\n",
        "            feature_values_new_audio = line_new_audio.strip().split(',')\n",
        "\n",
        "        # Crear un diccionario con las características y sus valores\n",
        "        feature_data_new_audio = {feature_names_new_audio[i]: float(feature_values_new_audio[i]) if feature_values_new_audio[i] != '?' else None for i in range(1, len(feature_values_new_audio))}\n",
        "        feature_data_new_audio['label'] = emotion\n",
        "\n",
        "        # Añadir las características a la lista de datos\n",
        "        data_new_audio.append(feature_data_new_audio)\n",
        "\n",
        "        # Combinar todos los datos en un DataFrame\n",
        "        df_new_audio = pd.DataFrame(data_new_audio)\n",
        "\n",
        "        # Guardar los datos en un archivo CSV\n",
        "        df_new_audio.to_csv(new_output_path, index=False)\n",
        "\n",
        "        # Leer las características extraídas\n",
        "        new_audio_features = pd.read_csv(new_output_path, delimiter=',')\n",
        "        new_audio_features = new_audio_features.drop(columns=['label', 'class'])\n",
        "\n",
        "        # Escalar las características del nuevo audio usando el mismo StandardScaler\n",
        "        new_audio_features = scaler.transform(new_audio_features)  # Apply the same scaling\n",
        "\n",
        "        # Predecir el sentimiento\n",
        "        prediction = model_voice.predict(new_audio_features)\n",
        "        predicted_label = encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
        "\n",
        "        nivel_satisfaccion_voz = \"\"\n",
        "\n",
        "        if predicted_label[0] in (\"VeryAngry\", \"VerySad\", \"VeryDisgust\"):\n",
        "          nivel_satisfaccion_voz = \"Very unsatisfied\"\n",
        "        elif predicted_label[0] in (\"Angry\", \"Sad\", \"Disgust\"):\n",
        "          nivel_satisfaccion_voz = \"Unsatisfied\"\n",
        "        elif predicted_label[0] in (\"Neutral\"):\n",
        "          nivel_satisfaccion_voz = \"Neutral\"\n",
        "        elif predicted_label[0] in (\"Happy\"):\n",
        "          nivel_satisfaccion_voz = \"Satisfied\"\n",
        "        elif predicted_label[0] in (\"VeryHappy\"):\n",
        "          nivel_satisfaccion_voz = \"Very satisfied\"\n",
        "\n",
        "\n",
        "        return nivel_satisfaccion_voz\n",
        "\n",
        "\n",
        "# Función para escribir el texto del audio\n",
        "def speech_to_text(audio, company, employee, calldate, participants):\n",
        "  try:\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio)\n",
        "    texto = result[\"text\"]\n",
        "    # Ruta destino del archivo en la carpeta deseada\n",
        "    dest_path = os.path.join(os.path.basename(audio))\n",
        "    shutil.move(audio, dest_path)\n",
        "    AudiosinExtension = os.path.splitext(dest_path)[0]\n",
        "\n",
        "    file = open(AudiosinExtension+\".txt\", \"w\")\n",
        "    file.write(texto)\n",
        "    file.close()\n",
        "\n",
        "    AnalisisSentimientoTexto = analisis_sentimiento_texto(texto, company, employee, calldate, participants,origen=\"1\")\n",
        "    AnalisisSentimientoVoz = analisis_sentimiento_voz(dest_path)\n",
        "\n",
        "    return AnalisisSentimientoVoz\n",
        "  except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    return f\"Se produjo un error: {e}\"\n",
        "\n",
        "def analisis_sentimiento_texto(text, company, employee, calldate, participants,origen):\n",
        "\n",
        "  # se separa el texto por lineas para hacer la separación\n",
        "  print(text)\n",
        "  lineas = text.split('\\n')\n",
        "  print(lineas)\n",
        "  # Lista para almacenar las líneas del cliente\n",
        "  lineas_cliente = []\n",
        "\n",
        "  # Variable para indicar si estamos dentro de un diálogo del cliente\n",
        "  es_dialogo = False\n",
        "\n",
        "  # Itera sobre las líneas del archivo\n",
        "  if origen == \"0\":\n",
        "      for linea in lineas:\n",
        "          if es_dialogo and linea != \"\":\n",
        "              lineas_cliente.append(linea.strip())\n",
        "\n",
        "          # Verifica si la línea actual es dicha por el cliente\n",
        "          if linea.startswith(employee):\n",
        "              es_dialogo = True\n",
        "          elif linea == '':\n",
        "              es_dialogo = False\n",
        "\n",
        "  elif origen==\"1\":\n",
        "      lineas_cliente=lineas[0].split('.')\n",
        "\n",
        "  # Imprimir el contenido en bloques de 15 líneas\n",
        "  bloque_size = 15\n",
        "  total_lineas = len(lineas_cliente)\n",
        "  valores = []\n",
        "  for i in range(0, total_lineas, bloque_size):\n",
        "    parrafo = ''\n",
        "    bloque = lineas_cliente[i:i + bloque_size]\n",
        "    for linea in bloque:\n",
        "        parrafo = parrafo + ' ' + linea.strip()\n",
        "    neg, neu, pos = analizar(parrafo)\n",
        "    valores.append([neg, neu, pos])\n",
        "\n",
        "  pneg, pneu, ppos = np.mean(valores, axis=0)\n",
        "  satisfaccion = clasificar_satisfaccion(pneg, pneu, ppos)\n",
        "  return satisfaccion\n",
        "\n",
        "def analizar(texto):\n",
        "  # creación del pipeline cargando el modelo preentrenado\n",
        "  pipe = pipeline(\n",
        "      model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
        "      top_k=None)\n",
        "  # obtención de la predicción\n",
        "  evaluacion = pipe(texto)[0]\n",
        "\n",
        "  # procesamiento de la respuesta del modelo\n",
        "  if evaluacion[0]['label']=='negative': neg = evaluacion[0]['score']\n",
        "  elif evaluacion[0]['label']=='positive': pos = evaluacion[0]['score']\n",
        "  else: neu = evaluacion[0]['score']\n",
        "\n",
        "  if evaluacion[1]['label']=='negative': neg = evaluacion[1]['score']\n",
        "  elif evaluacion[1]['label']=='positive': pos = evaluacion[1]['score']\n",
        "  else: neu = evaluacion[1]['score']\n",
        "\n",
        "  if evaluacion[2]['label']=='negative': neg = evaluacion[2]['score']\n",
        "  elif evaluacion[2]['label']=='positive': pos = evaluacion[2]['score']\n",
        "  else: neu = evaluacion[2]['score']\n",
        "\n",
        "  return (neg, neu, pos)\n",
        "\n",
        "# Definir los límites de cada categoría\n",
        "def clasificar_satisfaccion(negativo, neutro, positivo):\n",
        "    if positivo >= 0.8:\n",
        "        return \"Very satisfied\"\n",
        "    elif positivo >= 0.4 and positivo > negativo:\n",
        "        return \"Satisfied\"\n",
        "    elif negativo >= 0.8:\n",
        "        return \"Very unsatisfied\"\n",
        "    elif negativo >= 0.4 and negativo > positivo:\n",
        "        return \"Unsatisfied\"\n",
        "    elif neutro >= 0.4:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "styles = {\n",
        "     \"body\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"margin\": \"0\",\n",
        "        \"padding\": \"0\",\n",
        "        \"height\": \"100vh\",\n",
        "        \"display\": \"flex\",\n",
        "        \"justify-content\": \"center\",\n",
        "        \"align-items\": \"center\"\n",
        "    },\n",
        "    \".gradio-container\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"width\": \"100%\",\n",
        "        \"height\": \"100%\",\n",
        "        \"display\": \"flex\",\n",
        "        \"justify-content\": \"center\",\n",
        "        \"align-items\": \"center\"\n",
        "    },\n",
        "    \".lg.primary.svelte-cmf5ev\": {\n",
        "        \"background-color\": \"#5AAAF0\",\n",
        "        \"color\": \"white\",\n",
        "        \"font-size\": \"16px\",\n",
        "        \"border-radius\": \"125px\",\n",
        "        \"margin\": \"0px 10px\"\n",
        "    },\n",
        "     \".lg.secondary.svelte-cmf5ev\": {\n",
        "        \"background-color\": \"#B5B7CF\",\n",
        "        \"color\": \"white\",\n",
        "        \"font-weight\": \"bold\",\n",
        "        \"font-size\": \"16px\",\n",
        "        \"padding\": \"10px 20px\",\n",
        "        \"border-radius\": \"125px\",\n",
        "        \"margin\": \"20px 10px\"\n",
        "     },\n",
        "    \".svelte-1bvc1p0 th\": {\n",
        "        \"background-color\": \"#5AAAF0\",\n",
        "        \"color\": \"white\",\n",
        "        \"font-weight\": \"bold\",\n",
        "        \"font-size\": \"14px\",\n",
        "        \"border\": \"1px solid #ddd\",\n",
        "        \"text-align\": \"center\"\n",
        "    },\n",
        "    \".svelte-1bvc1p0 td\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"color\": \"black\",\n",
        "        \"border\": \"1px solid #ddd\",\n",
        "        \"text-align\": \"center\"\n",
        "    },\n",
        "     \".block.svelte-12cmxck\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"color\": \"black\",\n",
        "        \"text-align\": \"center\",\n",
        "        \"border\": \"1px solid white\"\n",
        "    },\n",
        "     \".svelte-1b6s6s\": {\n",
        "         \"display\": \"inline-block\",\n",
        "         \"background-color\": \"white\",\n",
        "         \"color\": \"black\",\n",
        "         \"border\": \"1px solid black\"\n",
        "    },\n",
        "     \".svelte-j5bxrl\": {\n",
        "         \"color\": \"#B5B7CF\",\n",
        "         \"background-color\": \"#B5B7CF\",\n",
        "         \"border\": \"1px solid black\"\n",
        "    },\n",
        "     \".svelte-j5bxrl svg\": {\n",
        "         \"color\": \"#B5B7CF\",\n",
        "         \"margin-right\": \"10px\"\n",
        "    },\n",
        "     \".wrap\": {\n",
        "        \"color\": \"black\"\n",
        "    },\n",
        "     \".or\": {\n",
        "         \"color\": \"black\"\n",
        "    },\n",
        "     \".svelte-1gfkn6j\": {\n",
        "         \"color\": \"black\"\n",
        "    },\n",
        "     \".svelte-sa48pu.stretch\":{\n",
        "         \"background-color\": \"white\",\n",
        "         \"border\": \"1px solid white\",\n",
        "         \"align-items\": \"center\",\n",
        "         \"justify-content\": \"center\"\n",
        "    },\n",
        "     \".svelte-iyf88w\": {\n",
        "         \"border\": \"1px solid white\"\n",
        "    },\n",
        "     \".svelte-1f354aw textarea\": {\n",
        "         \"border\": \"1px solid black\",\n",
        "         \"background-color\": \"#B5B7CF\",\n",
        "         \"font-weight\": \"bold\",\n",
        "         \"color\": \"black\"\n",
        "    },\n",
        "     \".svelte-vt1mxs\": {\n",
        "         \"padding\": \"0\"\n",
        "    },\n",
        "     \"#component-231\": {\n",
        "         \"margin-top\": \"10px\"\n",
        "    },\n",
        "     \".svelte-vt1mxs gap\": {\n",
        "         \"padding\": \"0\"\n",
        "     }\n",
        "}\n",
        "\n",
        "\n",
        "css_styles = \"\\n\".join([f\"{selector} {{{' '.join([f'{prop}: {value};' for prop, value in props.items()])}}}\" for selector, props in styles.items()])\n",
        "\n",
        "def on_upload_submit(file, company, employee, calldate, participants):\n",
        "    # Verificar que se haya subido un archivo\n",
        "    if file:\n",
        "        # Verificar si el archivo es un texto\n",
        "        if ((file.name).find('.txt') != -1):\n",
        "            with open(file.name, 'r') as f:\n",
        "                content = f.read()\n",
        "            valor = analisis_sentimiento_texto(content, company, employee, calldate, participants,origen=\"0\")\n",
        "            write_db(pfile_name=file.name, pupload_date=datetime.now().date(), pfile_size=100, pclient=company, pcalldate=calldate, pparticipants=int(participants), pemployee=employee, pai_value=valor)\n",
        "            return valor\n",
        "        # Verificar si el archivo es un audio\n",
        "        elif ((file.name).find('.wav') != -1):\n",
        "            audio_a_texto = speech_to_text(file, company, employee, calldate, participants)\n",
        "            write_db(pfile_name=file.name, pupload_date=datetime.now().date(), pfile_size=100, pclient=company, pcalldate=calldate, pparticipants=int(participants), pemployee=employee, pai_value=audio_a_texto)\n",
        "            return audio_a_texto\n",
        "        else:\n",
        "            return \"El archivo cargado no tiene formato .txt o .wav.\"\n",
        "    else:\n",
        "        return \"No se ha seleccionado ningún archivo.\"\n",
        "\n",
        "def query_to_DB(param_client):\n",
        "    try:\n",
        "        select_datos = '''select upload_date,\n",
        "        calldate,\n",
        "        employee,\n",
        "        client,\n",
        "        participants,\n",
        "        ai_value\n",
        "        from analisis_sentimientos\n",
        "        where client=:tagclient'''\n",
        "        cur_01.execute(select_datos, tagclient=param_client)\n",
        "        rows = cur_01.fetchall()\n",
        "        for row in rows:\n",
        "            print(row)\n",
        "        return rows\n",
        "    except Exception as err:\n",
        "        print(f\"Error:{err}\")\n",
        "        return f\"Se produjo un error: {err}\"\n",
        "\n",
        "with gr.Blocks(css=css_styles, theme=gr.themes.Monochrome()) as webpage:\n",
        "    markdown_text = \"\"\"\n",
        "    <div style='text-align: center; font-size: 36px; color: Black; font-weight: bold'>\n",
        "    Calls Sentiment Analysis\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    gr.Markdown(markdown_text)\n",
        "\n",
        "    # Crear botón cargar archivo, buscar y tabla de resultados\n",
        "    new_text_file_button = gr.Button(\"Upload .txt or .wav file\", variant=\"primary\")\n",
        "    new_query_button = gr.Button(\"Search call by Client\", variant=\"primary\")\n",
        "\n",
        "    # Crear los componentes para el archivo de texto\n",
        "    upload_file = gr.Group(visible=False)\n",
        "    query_db = gr.Group(visible=False)\n",
        "\n",
        "    with upload_file:\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"Select a File\", file_count=\"single\", file_types=[\".txt\", \".wav\" ], interactive=True)\n",
        "\n",
        "            with gr.Row():\n",
        "                company_input = gr.Textbox(label=\"Client\")\n",
        "                employee_input = gr.Textbox(label=\"Employee\")\n",
        "            with gr.Row():\n",
        "                calldate_input = gr.Textbox(label=\"Call date (YYYY-MM-DD)\")\n",
        "                participants_input = gr.Textbox(label=\"Participants\")\n",
        "            with gr.Row():\n",
        "                close_button = gr.Button(\"Close\", variant=\"secondary\")\n",
        "                upload_text_button = gr.Button(\"Upload\", variant=\"primary\")\n",
        "\n",
        "\n",
        "            upload_text_button.click(on_upload_submit, inputs=[file_input, company_input, employee_input, calldate_input, participants_input], outputs=[gr.Textbox(label=\"Sentiment Analysis\", lines=10)])\n",
        "            close_button.click(lambda: gr.update(visible=False), inputs=[], outputs=[upload_file])\n",
        "\n",
        "    with query_db:\n",
        "        with gr.Row():\n",
        "            cliente_query = gr.Textbox(label=\"Client\")\n",
        "            query_client_button = gr.Button(\"Search\", variant=\"primary\")\n",
        "        lista_datos_db = gr.Dataframe(headers=[\"Date uploaded\", \"Call Date\", \"Employee\", \"Client\", \"Participants\", \"AI Value\"],\n",
        "                                          datatype=[\"date\", \"date\", \"str\", \"str\", \"number\", \"str\"],\n",
        "                                          row_count=1)\n",
        "        query_client_button.click(query_to_DB, inputs=cliente_query, outputs=lista_datos_db)\n",
        "\n",
        "    new_query_button.click(lambda: gr.update(visible=True), inputs=[], outputs=[query_db])\n",
        "    new_text_file_button.click(lambda: gr.update(visible=True), inputs=[], outputs=[upload_file])\n",
        "\n",
        "webpage.launch()"
      ],
      "metadata": {
        "id": "aGE0LegCxmvp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "da49faca-a6cc-46be-cfee-82c8efb116eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.5.0.24.5\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4d014796b0c12616b0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4d014796b0c12616b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}