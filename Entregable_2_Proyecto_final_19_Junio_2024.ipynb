{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reth202/Tesis_Analisis_Del_Sentimiento/blob/main/Entregable_2_Proyecto_final_19_Junio_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QjF8Z0kxXqL"
      },
      "outputs": [],
      "source": [
        "username = \"USER_PROYFINAL\"\n",
        "dsn = \"dbproyfinal_high\"\n",
        "pw = \"UserProyFinal#40_24\"\n",
        "wallet_pw=\"^&$#7aBcdeFgHiJkLmNpQrStUvWxYz@!%\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR0pStP_9KU7",
        "outputId": "0ac63b8d-6e91-48b2-82ae-50156eedff5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mE2X7d2yxd7R"
      },
      "outputs": [],
      "source": [
        "!chmod +x /content/drive/MyDrive/TrabajoFinal/Codigo/ColabVersiones/opensmile-3.0.2-linux-x86_64/bin/SMILExtract\n",
        "!chmod +r \"/content/drive/MyDrive/TrabajoFinal/Codigo/ColabVersiones/opensmile-3.0.2-linux-x86_64/config/is09-13/IS09_emotion.conf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6TpYHQl2k5N"
      },
      "outputs": [],
      "source": [
        "path = 'C:\\Users\\Lenovo\\Documents\\Maestría\\Trabajo Final Tesis\\Entregable 3\\Tesis_Analisis_Del_Sentimiento\\Sentimientos\\'\n",
        "lst = []\n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "      try:\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
        "        file = file[6:8]\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      except ValueError:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdwC0wBs9hgs"
      },
      "outputs": [],
      "source": [
        "# Función para extraer características con OpenSMILE\n",
        "def extract_features(audio_path, output_path, config_path=\"C:\\Users\\Lenovo\\Documents\\Maestría\\Trabajo Final Tesis\\Entregable 3\\Tesis_Analisis_Del_Sentimiento\\opensmile-3.0.2-linux-x86_64\\config\\is09-13\\IS09_emotion.conf\"):\n",
        "    !chmod +r \"{config_path}\"\n",
        "\n",
        "    # Construir el comando para ejecutar OpenSMILE\n",
        "    command = f'\"C:\\Users\\Lenovo\\Documents\\Maestría\\Trabajo Final Tesis\\Entregable 3\\Tesis_Analisis_Del_Sentimiento\\opensmile-3.0.2-linux-x86_64\\bin\\SMILExtract\" -C \"{config_path}\" -I \"{audio_path}\" -O \"{output_path}\"'\n",
        "\n",
        "    # Ejecutar el comando y capturar el resultado\n",
        "    result = subprocess.run(command, shell=True, capture_output=True)\n",
        "\n",
        "    # Manejo de errores si el proceso no termina con éxito\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Error al ejecutar OpenSMILE:\\n{result.stderr.decode('utf-8')}\")\n",
        "        return \"Error al ejecutar OpenSMILE\"\n",
        "    else:\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDlWlX94234M"
      },
      "outputs": [],
      "source": [
        "# Directorio de datos\n",
        "data_dir = '/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/'\n",
        "output_dir = '/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/features'\n",
        "\n",
        "# Crear el directorio de salida si no existe\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Inicializar una lista para almacenar los datos\n",
        "data = []\n",
        "\n",
        "# Recorrer cada carpeta de emociones\n",
        "for emotion in os.listdir(data_dir):\n",
        "    emotion_dir = os.path.join(data_dir, emotion)\n",
        "    if os.path.isdir(emotion_dir):\n",
        "        # Recorrer cada archivo de audio en la carpeta de emociones\n",
        "        for audio_file in os.listdir(emotion_dir):\n",
        "            if audio_file.endswith('.wav'):\n",
        "                audio_path = os.path.join(emotion_dir, audio_file)\n",
        "                AudioSinLaExtension = os.path.splitext(audio_file)[0]\n",
        "                output_path = os.path.join(output_dir, f\"{emotion}_{AudioSinLaExtension}.csv\")\n",
        "\n",
        "                # Extraer características\n",
        "                extract_features(audio_path, output_path)\n",
        "\n",
        "                # Leer las características extraídas\n",
        "                with open(output_path, 'r') as file:\n",
        "                    lines = file.readlines()\n",
        "\n",
        "                # Encontrar la línea con los datos (después de @data)\n",
        "                data_start_index = lines.index('@data\\n') + 1\n",
        "\n",
        "                # Extraer los nombres de los atributos y los valores correspondientes\n",
        "                feature_names = []\n",
        "                feature_values = []\n",
        "\n",
        "                for line in lines:\n",
        "                    if line.startswith('@attribute'):\n",
        "                        parts = line.split()\n",
        "                        feature_names.append(parts[1])\n",
        "                    elif not line.startswith('@') and line.strip():\n",
        "                        feature_values = line.strip().split(',')\n",
        "\n",
        "\n",
        "                # Crear un diccionario con las características y sus valores\n",
        "                feature_data = {feature_names[i]: float(feature_values[i]) if feature_values[i] != '?' else None for i in range(1, len(feature_values))}\n",
        "                feature_data['label'] = emotion\n",
        "\n",
        "                # Añadir las características a la lista de datos\n",
        "                data.append(feature_data)\n",
        "\n",
        "# Combinar todos los datos en un DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Guardar los datos en un archivo CSV\n",
        "df.to_csv('/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/features/features.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWZDdK9s30Lp",
        "outputId": "e49cd2c7-a166-4337-f0ef-6b19b4614103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50/50 [==============================] - 3s 14ms/step - loss: 0.5195 - accuracy: 0.8712 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 0.9987 - val_loss: 0.0227 - val_accuracy: 0.9950\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9950\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 0.9975\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9975\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9975\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9975\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 8.5607e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9975\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 6.9323e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9975\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 5.7360e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 4.8023e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9975\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 4.1006e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9975\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 3.5424e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 3.0806e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9975\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 2.7074e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 2.4029e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9975\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 2.1424e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9975\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.9234e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9975\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - 0s 5ms/step - loss: 1.7346e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9975\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - 0s 4ms/step - loss: 1.5722e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9975\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9975\n",
            "Accuracy: 0.9975000023841858\n"
          ]
        }
      ],
      "source": [
        "# Leer el archivo CSV de características\n",
        "data = pd.read_csv('/content/drive/MyDrive/TrabajoFinal/Dataset_Entrenamiento/features/features.csv')\n",
        "\n",
        "# Separar características y etiquetas, excluyendo la columna 'class'\n",
        "X = data.drop(columns=['label', 'class'])\n",
        "y = data['label']\n",
        "\n",
        "# Codificar las etiquetas\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Convertir todas las columnas a numéricas (ignorando errores)\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Eliminar filas con valores faltantes después de la conversión\n",
        "X = X.dropna()\n",
        "y_encoded = y_encoded[X.index]  # Ajustar y_encoded para coincidir con el índice de X\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características usando StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir el modelo\n",
        "model_voice = Sequential()\n",
        "model_voice.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model_voice.add(Dense(64, activation='relu'))\n",
        "model_voice.add(Dense(len(encoder.classes_), activation='softmax'))  # Asumiendo 3 clases de salida\n",
        "\n",
        "# Compilar el modelo\n",
        "model_voice.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_voice.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluar el modelo\n",
        "loss, accuracy = model_voice.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "aGE0LegCxmvp",
        "outputId": "da49faca-a6cc-46be-cfee-82c8efb116eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23.5.0.24.5\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4d014796b0c12616b0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://4d014796b0c12616b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Establishing a connection to the Oracle database\n",
        "try:\n",
        "    conn = oracledb.connect(\n",
        "    user= username,\n",
        "    password= pw,\n",
        "    dsn= dsn,\n",
        "    #Colocar ruta del walet en la maquina donde se ejecute, el wallet debe estar descomprimido\n",
        "    config_dir=r'/content/drive/MyDrive/TrabajoFinal/Codigo/DB/Wallet_DBPROYFINAL',\n",
        "    wallet_location=r'/content/drive/MyDrive/TrabajoFinal/Codigo/DB/Wallet_DBPROYFINAL',\n",
        "    wallet_password=wallet_pw\n",
        "    )\n",
        "    # Print the version of the database to confirm connection\n",
        "    print(conn.version)\n",
        "except Exception as err:\n",
        "    print(\"Error en la conexión a la base de datos\", err)\n",
        "\n",
        "cur_01=conn.cursor()\n",
        "\n",
        "\n",
        "##Cierra la conexion de la base de datos\n",
        "#conn.close()\n",
        "\n",
        "def write_db(pfile_name, pupload_date, pfile_size, pclient, pcalldate, pparticipants,  pemployee, pai_value):\n",
        "    ##Instrucciones para consultar datos de la tabla prueba2\n",
        "    try:\n",
        "        insert_datos = '''insert into analisis_sentimientos(file_name,\n",
        "        upload_date,\n",
        "        file_size,\n",
        "        client,\n",
        "        calldate,\n",
        "        participants,\n",
        "        employee,\n",
        "        ai_value)\n",
        "        values(:tagfile_name, :tagupload_date, :tagfile_size, :tagclient, :tagcalldate, :tagparticipants,  :tagemployee, :tagai_value)'''\n",
        "        cur_01.execute(insert_datos,tagfile_name=pfile_name, tagupload_date=pupload_date, tagfile_size=pfile_size, tagclient=pclient, tagcalldate=pcalldate, tagparticipants=pparticipants,  tagemployee=pemployee,tagai_value=pai_value)\n",
        "    except Exception as err:\n",
        "        print(\"Error insertando datos\",err)\n",
        "    else:\n",
        "        print(\"Datos insertados correctamente\")\n",
        "        conn.commit()\n",
        "\n",
        "def analisis_sentimiento_voz(audio_path):\n",
        "\n",
        "    audio_sin_extension = os.path.splitext(audio_path)[0]\n",
        "\n",
        "    new_output_path = os.path.join(\"/content/drive/MyDrive/TrabajoFinal/AudiosCargados/\", audio_sin_extension+\".csv\")\n",
        "\n",
        "    output_dir_audio = \"/content/drive/MyDrive/TrabajoFinal/AudiosCargados/\"\n",
        "\n",
        "    # Crear el directorio de salida si no existe\n",
        "    os.makedirs(output_dir_audio, exist_ok=True)\n",
        "\n",
        "    # Inicializar una lista para almacenar los datos\n",
        "    data_new_audio = []\n",
        "\n",
        "    # Extraer características del nuevo archivo de audio\n",
        "    valor = extract_features(audio_path, new_output_path)\n",
        "\n",
        "    if valor == \"Error al ejecutar OpenSMILE\":\n",
        "      return \"Error al extraer características del nuevo archivo de audio\"\n",
        "\n",
        "    else:\n",
        "        with open(new_output_path, 'r') as file:\n",
        "            lines_new_audio = file.readlines()\n",
        "\n",
        "        # Encontrar la línea con los datos (después de @data)\n",
        "        data_start_index = lines.index('@data\\n') + 1\n",
        "\n",
        "        # Extraer los nombres de los atributos y los valores correspondientes\n",
        "        feature_names_new_audio = []\n",
        "        feature_values_new_audio = []\n",
        "\n",
        "        for line_new_audio in lines_new_audio:\n",
        "          if line_new_audio.startswith('@attribute'):\n",
        "            parts = line_new_audio.split()\n",
        "            feature_names_new_audio.append(parts[1])\n",
        "          elif not line_new_audio.startswith('@') and line_new_audio.strip():\n",
        "            feature_values_new_audio = line_new_audio.strip().split(',')\n",
        "\n",
        "        # Crear un diccionario con las características y sus valores\n",
        "        feature_data_new_audio = {feature_names_new_audio[i]: float(feature_values_new_audio[i]) if feature_values_new_audio[i] != '?' else None for i in range(1, len(feature_values_new_audio))}\n",
        "        feature_data_new_audio['label'] = emotion\n",
        "\n",
        "        # Añadir las características a la lista de datos\n",
        "        data_new_audio.append(feature_data_new_audio)\n",
        "\n",
        "        # Combinar todos los datos en un DataFrame\n",
        "        df_new_audio = pd.DataFrame(data_new_audio)\n",
        "\n",
        "        # Guardar los datos en un archivo CSV\n",
        "        df_new_audio.to_csv(new_output_path, index=False)\n",
        "\n",
        "        # Leer las características extraídas\n",
        "        new_audio_features = pd.read_csv(new_output_path, delimiter=',')\n",
        "        new_audio_features = new_audio_features.drop(columns=['label', 'class'])\n",
        "\n",
        "        # Escalar las características del nuevo audio usando el mismo StandardScaler\n",
        "        new_audio_features = scaler.transform(new_audio_features)  # Apply the same scaling\n",
        "\n",
        "        # Predecir el sentimiento\n",
        "        prediction = model_voice.predict(new_audio_features)\n",
        "        predicted_label = encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
        "\n",
        "        nivel_satisfaccion_voz = \"\"\n",
        "\n",
        "        if predicted_label[0] in (\"VeryAngry\", \"VerySad\", \"VeryDisgust\"):\n",
        "          nivel_satisfaccion_voz = \"Very unsatisfied\"\n",
        "        elif predicted_label[0] in (\"Angry\", \"Sad\", \"Disgust\"):\n",
        "          nivel_satisfaccion_voz = \"Unsatisfied\"\n",
        "        elif predicted_label[0] in (\"Neutral\"):\n",
        "          nivel_satisfaccion_voz = \"Neutral\"\n",
        "        elif predicted_label[0] in (\"Happy\"):\n",
        "          nivel_satisfaccion_voz = \"Satisfied\"\n",
        "        elif predicted_label[0] in (\"VeryHappy\"):\n",
        "          nivel_satisfaccion_voz = \"Very satisfied\"\n",
        "\n",
        "\n",
        "        return nivel_satisfaccion_voz\n",
        "\n",
        "\n",
        "# Función para escribir el texto del audio\n",
        "def speech_to_text(audio, company, employee, calldate, participants):\n",
        "  try:\n",
        "    model = whisper.load_model(\"base\")\n",
        "    result = model.transcribe(audio)\n",
        "    texto = result[\"text\"]\n",
        "    # Ruta destino del archivo en la carpeta deseada\n",
        "    dest_path = os.path.join(os.path.basename(audio))\n",
        "    shutil.move(audio, dest_path)\n",
        "    AudiosinExtension = os.path.splitext(dest_path)[0]\n",
        "\n",
        "    file = open(AudiosinExtension+\".txt\", \"w\")\n",
        "    file.write(texto)\n",
        "    file.close()\n",
        "\n",
        "    AnalisisSentimientoTexto = analisis_sentimiento_texto(texto, company, employee, calldate, participants,origen=\"1\")\n",
        "    AnalisisSentimientoVoz = analisis_sentimiento_voz(dest_path)\n",
        "\n",
        "    return AnalisisSentimientoVoz\n",
        "  except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    return f\"Se produjo un error: {e}\"\n",
        "\n",
        "def analisis_sentimiento_texto(text, company, employee, calldate, participants,origen):\n",
        "\n",
        "  # se separa el texto por lineas para hacer la separación\n",
        "  print(text)\n",
        "  lineas = text.split('\\n')\n",
        "  print(lineas)\n",
        "  # Lista para almacenar las líneas del cliente\n",
        "  lineas_cliente = []\n",
        "\n",
        "  # Variable para indicar si estamos dentro de un diálogo del cliente\n",
        "  es_dialogo = False\n",
        "\n",
        "  # Itera sobre las líneas del archivo\n",
        "  if origen == \"0\":\n",
        "      for linea in lineas:\n",
        "          if es_dialogo and linea != \"\":\n",
        "              lineas_cliente.append(linea.strip())\n",
        "\n",
        "          # Verifica si la línea actual es dicha por el cliente\n",
        "          if linea.startswith(employee):\n",
        "              es_dialogo = True\n",
        "          elif linea == '':\n",
        "              es_dialogo = False\n",
        "\n",
        "  elif origen==\"1\":\n",
        "      lineas_cliente=lineas[0].split('.')\n",
        "\n",
        "  # Imprimir el contenido en bloques de 15 líneas\n",
        "  bloque_size = 15\n",
        "  total_lineas = len(lineas_cliente)\n",
        "  valores = []\n",
        "  for i in range(0, total_lineas, bloque_size):\n",
        "    parrafo = ''\n",
        "    bloque = lineas_cliente[i:i + bloque_size]\n",
        "    for linea in bloque:\n",
        "        parrafo = parrafo + ' ' + linea.strip()\n",
        "    neg, neu, pos = analizar(parrafo)\n",
        "    valores.append([neg, neu, pos])\n",
        "\n",
        "  pneg, pneu, ppos = np.mean(valores, axis=0)\n",
        "  satisfaccion = clasificar_satisfaccion(pneg, pneu, ppos)\n",
        "  return satisfaccion\n",
        "\n",
        "def analizar(texto):\n",
        "  # creación del pipeline cargando el modelo preentrenado\n",
        "  pipe = pipeline(\n",
        "      model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
        "      top_k=None)\n",
        "  # obtención de la predicción\n",
        "  evaluacion = pipe(texto)[0]\n",
        "\n",
        "  # procesamiento de la respuesta del modelo\n",
        "  if evaluacion[0]['label']=='negative': neg = evaluacion[0]['score']\n",
        "  elif evaluacion[0]['label']=='positive': pos = evaluacion[0]['score']\n",
        "  else: neu = evaluacion[0]['score']\n",
        "\n",
        "  if evaluacion[1]['label']=='negative': neg = evaluacion[1]['score']\n",
        "  elif evaluacion[1]['label']=='positive': pos = evaluacion[1]['score']\n",
        "  else: neu = evaluacion[1]['score']\n",
        "\n",
        "  if evaluacion[2]['label']=='negative': neg = evaluacion[2]['score']\n",
        "  elif evaluacion[2]['label']=='positive': pos = evaluacion[2]['score']\n",
        "  else: neu = evaluacion[2]['score']\n",
        "\n",
        "  return (neg, neu, pos)\n",
        "\n",
        "# Definir los límites de cada categoría\n",
        "def clasificar_satisfaccion(negativo, neutro, positivo):\n",
        "    if positivo >= 0.8:\n",
        "        return \"Very satisfied\"\n",
        "    elif positivo >= 0.4 and positivo > negativo:\n",
        "        return \"Satisfied\"\n",
        "    elif negativo >= 0.8:\n",
        "        return \"Very unsatisfied\"\n",
        "    elif negativo >= 0.4 and negativo > positivo:\n",
        "        return \"Unsatisfied\"\n",
        "    elif neutro >= 0.4:\n",
        "        return \"Neutral\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "styles = {\n",
        "     \"body\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"margin\": \"0\",\n",
        "        \"padding\": \"0\",\n",
        "        \"height\": \"100vh\",\n",
        "        \"display\": \"flex\",\n",
        "        \"justify-content\": \"center\",\n",
        "        \"align-items\": \"center\"\n",
        "    },\n",
        "    \".gradio-container\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"width\": \"100%\",\n",
        "        \"height\": \"100%\",\n",
        "        \"display\": \"flex\",\n",
        "        \"justify-content\": \"center\",\n",
        "        \"align-items\": \"center\"\n",
        "    },\n",
        "    \".lg.primary.svelte-cmf5ev\": {\n",
        "        \"background-color\": \"#5AAAF0\",\n",
        "        \"color\": \"white\",\n",
        "        \"font-size\": \"16px\",\n",
        "        \"border-radius\": \"125px\",\n",
        "        \"margin\": \"0px 10px\"\n",
        "    },\n",
        "     \".lg.secondary.svelte-cmf5ev\": {\n",
        "        \"background-color\": \"#B5B7CF\",\n",
        "        \"color\": \"white\",\n",
        "        \"font-weight\": \"bold\",\n",
        "        \"font-size\": \"16px\",\n",
        "        \"padding\": \"10px 20px\",\n",
        "        \"border-radius\": \"125px\",\n",
        "        \"margin\": \"20px 10px\"\n",
        "     },\n",
        "    \".svelte-1bvc1p0 th\": {\n",
        "        \"background-color\": \"#5AAAF0\",\n",
        "        \"color\": \"white\",\n",
        "        \"font-weight\": \"bold\",\n",
        "        \"font-size\": \"14px\",\n",
        "        \"border\": \"1px solid #ddd\",\n",
        "        \"text-align\": \"center\"\n",
        "    },\n",
        "    \".svelte-1bvc1p0 td\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"color\": \"black\",\n",
        "        \"border\": \"1px solid #ddd\",\n",
        "        \"text-align\": \"center\"\n",
        "    },\n",
        "     \".block.svelte-12cmxck\": {\n",
        "        \"background-color\": \"white\",\n",
        "        \"color\": \"black\",\n",
        "        \"text-align\": \"center\",\n",
        "        \"border\": \"1px solid white\"\n",
        "    },\n",
        "     \".svelte-1b6s6s\": {\n",
        "         \"display\": \"inline-block\",\n",
        "         \"background-color\": \"white\",\n",
        "         \"color\": \"black\",\n",
        "         \"border\": \"1px solid black\"\n",
        "    },\n",
        "     \".svelte-j5bxrl\": {\n",
        "         \"color\": \"#B5B7CF\",\n",
        "         \"background-color\": \"#B5B7CF\",\n",
        "         \"border\": \"1px solid black\"\n",
        "    },\n",
        "     \".svelte-j5bxrl svg\": {\n",
        "         \"color\": \"#B5B7CF\",\n",
        "         \"margin-right\": \"10px\"\n",
        "    },\n",
        "     \".wrap\": {\n",
        "        \"color\": \"black\"\n",
        "    },\n",
        "     \".or\": {\n",
        "         \"color\": \"black\"\n",
        "    },\n",
        "     \".svelte-1gfkn6j\": {\n",
        "         \"color\": \"black\"\n",
        "    },\n",
        "     \".svelte-sa48pu.stretch\":{\n",
        "         \"background-color\": \"white\",\n",
        "         \"border\": \"1px solid white\",\n",
        "         \"align-items\": \"center\",\n",
        "         \"justify-content\": \"center\"\n",
        "    },\n",
        "     \".svelte-iyf88w\": {\n",
        "         \"border\": \"1px solid white\"\n",
        "    },\n",
        "     \".svelte-1f354aw textarea\": {\n",
        "         \"border\": \"1px solid black\",\n",
        "         \"background-color\": \"#B5B7CF\",\n",
        "         \"font-weight\": \"bold\",\n",
        "         \"color\": \"black\"\n",
        "    },\n",
        "     \".svelte-vt1mxs\": {\n",
        "         \"padding\": \"0\"\n",
        "    },\n",
        "     \"#component-231\": {\n",
        "         \"margin-top\": \"10px\"\n",
        "    },\n",
        "     \".svelte-vt1mxs gap\": {\n",
        "         \"padding\": \"0\"\n",
        "     }\n",
        "}\n",
        "\n",
        "\n",
        "css_styles = \"\\n\".join([f\"{selector} {{{' '.join([f'{prop}: {value};' for prop, value in props.items()])}}}\" for selector, props in styles.items()])\n",
        "\n",
        "def on_upload_submit(file, company, employee, calldate, participants):\n",
        "    # Verificar que se haya subido un archivo\n",
        "    if file:\n",
        "        # Verificar si el archivo es un texto\n",
        "        if ((file.name).find('.txt') != -1):\n",
        "            with open(file.name, 'r') as f:\n",
        "                content = f.read()\n",
        "            valor = analisis_sentimiento_texto(content, company, employee, calldate, participants,origen=\"0\")\n",
        "            write_db(pfile_name=file.name, pupload_date=datetime.now().date(), pfile_size=100, pclient=company, pcalldate=calldate, pparticipants=int(participants), pemployee=employee, pai_value=valor)\n",
        "            return valor\n",
        "        # Verificar si el archivo es un audio\n",
        "        elif ((file.name).find('.wav') != -1):\n",
        "            audio_a_texto = speech_to_text(file, company, employee, calldate, participants)\n",
        "            write_db(pfile_name=file.name, pupload_date=datetime.now().date(), pfile_size=100, pclient=company, pcalldate=calldate, pparticipants=int(participants), pemployee=employee, pai_value=audio_a_texto)\n",
        "            return audio_a_texto\n",
        "        else:\n",
        "            return \"El archivo cargado no tiene formato .txt o .wav.\"\n",
        "    else:\n",
        "        return \"No se ha seleccionado ningún archivo.\"\n",
        "\n",
        "def query_to_DB(param_client):\n",
        "    try:\n",
        "        select_datos = '''select upload_date,\n",
        "        calldate,\n",
        "        employee,\n",
        "        client,\n",
        "        participants,\n",
        "        ai_value\n",
        "        from analisis_sentimientos\n",
        "        where client=:tagclient'''\n",
        "        cur_01.execute(select_datos, tagclient=param_client)\n",
        "        rows = cur_01.fetchall()\n",
        "        for row in rows:\n",
        "            print(row)\n",
        "        return rows\n",
        "    except Exception as err:\n",
        "        print(f\"Error:{err}\")\n",
        "        return f\"Se produjo un error: {err}\"\n",
        "\n",
        "with gr.Blocks(css=css_styles, theme=gr.themes.Monochrome()) as webpage:\n",
        "    markdown_text = \"\"\"\n",
        "    <div style='text-align: center; font-size: 36px; color: Black; font-weight: bold'>\n",
        "    Calls Sentiment Analysis\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    gr.Markdown(markdown_text)\n",
        "\n",
        "    # Crear botón cargar archivo, buscar y tabla de resultados\n",
        "    new_text_file_button = gr.Button(\"Upload .txt or .wav file\", variant=\"primary\")\n",
        "    new_query_button = gr.Button(\"Search call by Client\", variant=\"primary\")\n",
        "\n",
        "    # Crear los componentes para el archivo de texto\n",
        "    upload_file = gr.Group(visible=False)\n",
        "    query_db = gr.Group(visible=False)\n",
        "\n",
        "    with upload_file:\n",
        "        with gr.Row():\n",
        "            file_input = gr.File(label=\"Select a File\", file_count=\"single\", file_types=[\".txt\", \".wav\" ], interactive=True)\n",
        "\n",
        "            with gr.Row():\n",
        "                company_input = gr.Textbox(label=\"Client\")\n",
        "                employee_input = gr.Textbox(label=\"Employee\")\n",
        "            with gr.Row():\n",
        "                calldate_input = gr.Textbox(label=\"Call date (YYYY-MM-DD)\")\n",
        "                participants_input = gr.Textbox(label=\"Participants\")\n",
        "            with gr.Row():\n",
        "                close_button = gr.Button(\"Close\", variant=\"secondary\")\n",
        "                upload_text_button = gr.Button(\"Upload\", variant=\"primary\")\n",
        "\n",
        "\n",
        "            upload_text_button.click(on_upload_submit, inputs=[file_input, company_input, employee_input, calldate_input, participants_input], outputs=[gr.Textbox(label=\"Sentiment Analysis\", lines=10)])\n",
        "            close_button.click(lambda: gr.update(visible=False), inputs=[], outputs=[upload_file])\n",
        "\n",
        "    with query_db:\n",
        "        with gr.Row():\n",
        "            cliente_query = gr.Textbox(label=\"Client\")\n",
        "            query_client_button = gr.Button(\"Search\", variant=\"primary\")\n",
        "        lista_datos_db = gr.Dataframe(headers=[\"Date uploaded\", \"Call Date\", \"Employee\", \"Client\", \"Participants\", \"AI Value\"],\n",
        "                                          datatype=[\"date\", \"date\", \"str\", \"str\", \"number\", \"str\"],\n",
        "                                          row_count=1)\n",
        "        query_client_button.click(query_to_DB, inputs=cliente_query, outputs=lista_datos_db)\n",
        "\n",
        "    new_query_button.click(lambda: gr.update(visible=True), inputs=[], outputs=[query_db])\n",
        "    new_text_file_button.click(lambda: gr.update(visible=True), inputs=[], outputs=[upload_file])\n",
        "\n",
        "webpage.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
